{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWUK25s9YosK"
   },
   "source": [
    "# 4. Web Scraping - Scrapy\n",
    "\n",
    "<img src='https://xn--kvin-duranty-beb.fr/wp-content/uploads/2022/10/Web-Scraping-_-IPSSI-PRS-3.png'>\n",
    "\n",
    "Dans cet exercice, nous utiliserons la bibliothèque scrapy afin de collecter les données des sites internet suivants :\n",
    "\n",
    "- Partie 1 : [AlloCiné](https://www.allocine.fr/film/meilleurs)\n",
    "Nous collecterons les informations des meilleurs films recensés par la platforme.\n",
    "\n",
    "\n",
    "- Partie 2 : [Boursorama](https://www.boursorama.com/bourse/actions/palmares/france/page-1?france_filter%5Bmarket%5D=1rPCAC)\n",
    "Nous collecterons les données boursières des entreprises du CAC40.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5kwWF7QiXLH"
   },
   "source": [
    "# Parie 1 - Les meilleurs films selon [Allociné.fr](https://www.allocine.fr/film/meilleurs/)\n",
    "\n",
    "<img src= 'https://fr.web.img2.acsta.net/newsv7/15/10/19/21/14/237930.jpg'>\n",
    "\n",
    "L'objectif de cet exercice est de collecter les données des meilleurs films présents sur la page `https://www.allocine.fr/film/meilleurs/` du site allocine.fr.\n",
    "\n",
    "Les données que nous collecterons seront les suivantes :\n",
    "- Les titres du film\n",
    "- Les liens des images\n",
    "- Les noms des auteurs\n",
    "- Les durées des films\n",
    "- Les genres cinématographiques \n",
    "- Les scores des films\n",
    "- Les descriptions des films\n",
    "- Les dates de sortie des films\n",
    "\n",
    "## 4.1 Installez scrapy à l'aide de la commande suivante :\n",
    "\n",
    "\n",
    "`pip install scrapy`\n",
    "\n",
    "\n",
    "## 4.2 Générez un environement de travail scrapy en executant la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SSXagNDniXLI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: scrapy.cfg already exists in C:\\Users\\lahou\\Documents\\IPSSI\\WebScraping\\WebCrawler\n"
     ]
    }
   ],
   "source": [
    "# Création du dossier WebCrawler contenant l'ensemble des fichiers utiles au fonctionnement de scrapy\n",
    "!scrapy startproject WebCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dvKu-RjMiXLJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\", line 263, in _open_connection\n",
      "    self._cmysql.connect(**cnx_kwargs)\n",
      "_mysql_connector.MySQLInterfaceError: Can't connect to MySQL server on 'localhost:3306' (10061)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\Scripts\\scrapy-script.py\", line 10, in <module>\n",
      "    sys.exit(execute())\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\cmdline.py\", line 144, in execute\n",
      "    cmd.crawler_process = CrawlerProcess(settings)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 290, in __init__\n",
      "    super().__init__(settings)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 167, in __init__\n",
      "    self.spider_loader = self._get_spider_loader(settings)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 161, in _get_spider_loader\n",
      "    return loader_cls.from_settings(settings.frozencopy())\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 67, in from_settings\n",
      "    return cls(settings)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 24, in __init__\n",
      "    self._load_all_spiders()\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 51, in _load_all_spiders\n",
      "    for module in walk_modules(name):\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 88, in walk_modules\n",
      "    submod = import_module(fullpath)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\lahou\\Documents\\IPSSI\\WebScraping\\WebCrawler\\WebCrawler\\spiders\\allocine.py\", line 4, in <module>\n",
      "    from utiles import DataBase\n",
      "  File \"C:\\Users/lahou/Documents/IPSSI/WebScraping\\utiles.py\", line 4, in <module>\n",
      "    bddConnect = mysql.connector.connect(\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\mysql\\connector\\pooling.py\", line 286, in connect\n",
      "    return CMySQLConnection(*args, **kwargs)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\", line 101, in __init__\n",
      "    self.connect(**kwargs)\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\mysql\\connector\\abstracts.py\", line 1095, in connect\n",
      "    self._open_connection()\n",
      "  File \"C:\\Users\\lahou\\anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\", line 268, in _open_connection\n",
      "    raise get_mysql_exception(\n",
      "mysql.connector.errors.DatabaseError: 2003 (HY000): Can't connect to MySQL server on 'localhost:3306' (10061)\n"
     ]
    }
   ],
   "source": [
    "# Création du projet AlloCiné dans le dossier WebCrawler/spider\n",
    "!cd WebCrawler && scrapy genspider allocine https://www.allocine.fr/film/meilleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyGgGtBPiXLK"
   },
   "source": [
    "Les fichiers de scrapy que nous manipulerons seront :\n",
    "\n",
    "1. le fichier `items.py` qui contient les champs que nous souhaitons collecter (ex : nom des films, score, date de publication). Chaque champs sera introduit dans la class `ReviewsAllocineItem` avec la nomenclature suivante : `name = scrapy.Field()`.\n",
    "\n",
    "\n",
    "2. le fichier `allocine.py` qui contient les fonctions qui permetons la collecte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B58lLGGkiXLK"
   },
   "source": [
    "## 4.3 Ajoutez dans le fichier `items.py` les champs que nous souhaitons collecter.\n",
    "\n",
    "Ajoutez dans la class `ReviewsAllocineItem(scrapy.Item)` les champs suivants,\n",
    "pour rappel la nomenclature des champs est la suivante : \n",
    "\n",
    "`name = scrapy.Field()`.\n",
    "\n",
    "- title\n",
    "- img\n",
    "- author\n",
    "- time\n",
    "- genre\n",
    "- score\n",
    "- desc\n",
    "- release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m59XddkMiXLL"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scrapy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#À ajouter au fichier items.py\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mReviewsAllocineItem\u001b[39;00m(\u001b[43mscrapy\u001b[49m\u001b[38;5;241m.\u001b[39mItem):\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scrapy' is not defined"
     ]
    }
   ],
   "source": [
    "#À ajouter au fichier items.py\n",
    "class ReviewsAllocineItem(scrapy.Item):\n",
    "     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-oa-axJiXLM"
   },
   "source": [
    "## 4.3 Lancez votre terminal puis exécutez la commande suivante :\n",
    "\n",
    "C'est dans le terminale que nous intéragirons avec scrapy pour manipuler les bases du site allocine.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fpm98jI_iXLM"
   },
   "source": [
    "`scrapy shell`\n",
    "\n",
    "`url = 'https://www.allocine.fr/film/meilleurs'`\n",
    "\n",
    "`fetch(url)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6Y4IOoriXLN"
   },
   "source": [
    "## 4.4 Exécutez dans votre terminal les commandes suivantes et notez vos observations.\n",
    "\n",
    "Repérez en parallèle à quelles balises correspondent vos résultats.\n",
    "\n",
    "`response`\n",
    "\n",
    "`response.css('a')`\n",
    "\n",
    "`len(response.css('a'))`\n",
    "\n",
    "`response.css('a::text')`\n",
    "\n",
    "`response.css('a')[0].attrib`\n",
    "\n",
    "`response.css('a')[0].attrib['href']`\n",
    "\n",
    "`response.css('a::text')[0].extract()`\n",
    "\n",
    "`response.css('h1.item')`\n",
    "\n",
    "`response.css('h1.item::text')`\n",
    "\n",
    "`response.css('h1.item::text')[0].extract()`\n",
    "\n",
    "`response.css('img')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w6RdofbiXLN"
   },
   "source": [
    "## 4.5 Recherchez les informations suivantes sous forme de chaine de caractère (str) :\n",
    "\n",
    "0. La balise qui liste l'ensemble des films\n",
    "1. Le titre du premier film\n",
    "2. Le lien de l'image du premier film\n",
    "3. Le nom de l'auteur du premier film\n",
    "4. La durée du premier film \n",
    "5. Le genre cinématographique du premier film\n",
    "6. Le score du premier film\n",
    "7. La description du premier film\n",
    "8. La date de sortie du premier film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ya8Hcm3XiXLN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 0. La balise qui liste l'ensemble des films\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241m.\u001b[39mcss(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli.mdl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#1. Le titre du premier film\u001b[39;00m\n\u001b[0;32m      5\u001b[0m response\u001b[38;5;241m.\u001b[39mcss(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli.mdl\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcss(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma.meta-title-link::text\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mextract()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "# 0. La balise qui liste l'ensemble des films\n",
    "response.css('li.mdl')\n",
    "\n",
    "#1. Le titre du premier film\n",
    "response.css('li.mdl')[0].css('a.meta-title-link::text').extract()\n",
    "\n",
    "#2. Le lien de l'image du premier film\n",
    "response.css('li.mdl')[0].css('img.thumbnail-img').attrib['src']\n",
    "\n",
    "#3. Le nom de l'auteur du premier film\n",
    "response.css('li.mdl')[0].css('a.blue-link::text').extract()\n",
    "\n",
    "#4. La durée du premier film \n",
    "response.css('li.mdl')[0].css('div.meta-body-item.meta-body-info::text')[0].extract()\n",
    "\n",
    "#5. Le genre cinématographique du premier film\n",
    "response.css('li.mdl')[0].css('div.meta-body-item.meta-body-info')[0].css('span::text')[1:].extract()\n",
    "\n",
    "#6. Le score du premier film\n",
    "response.css('li.mdl')[0].css('span.stareval-note::text')[:-1].extract()\n",
    "\n",
    "#7. La description du premier film\n",
    "response.css('li.mdl')[0].css('div.content-txt::text').extract()\n",
    "\n",
    "#8. La date de sortie du premier film\n",
    "response.css('li.mdl')[0].css('span.date::text').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOl4emv1iXLO"
   },
   "source": [
    "## 4.6 Complétez le code suivante en fonction des résultats obtenus à la question précédentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3baQj3V4iXLO",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'WebCrawler.items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mWebCrawler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mitems\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReviewsAllocineItem\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAllocineSpider\u001b[39;00m(scrapy\u001b[38;5;241m.\u001b[39mSpider):\n\u001b[0;32m      7\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallocine\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'WebCrawler.items'"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy import Request\n",
    "from WebCrawler.items import ReviewsAllocineItem\n",
    "\n",
    "\n",
    "class AllocineSpider(scrapy.Spider):\n",
    "    name = 'allocine'\n",
    "    allowed_domains = ['www.allocine.fr']\n",
    "    \n",
    "    #Liste des pages à collecter\n",
    "    start_urls = [f'https://www.allocine.fr/film/meilleurs/?page={n}' for n in range(1,10)]\n",
    "\n",
    "\n",
    "    def start_requests(self):\n",
    "        for url in self.start_urls:\n",
    "            yield Request(url=url, callback=self.parse_manga)\n",
    "        \n",
    "        \n",
    "    def parse_manga(self, response):\n",
    "        liste_film = response.css('li.mdl')\n",
    "        \n",
    "        \n",
    "        # Boucle qui parcours l'ensemble des éléments de la liste des films\n",
    "        for film in liste_film:\n",
    "            item = ReviewsAllocineItem()\n",
    "\n",
    "            # Nom du film\n",
    "            try:\n",
    "                item['title'] = film.css('a.meta-title-link::text').extract()\n",
    "            except:\n",
    "                item['title'] = 'None'\n",
    "              \n",
    "            # Lien de l'image du film\n",
    "            try:\n",
    "                item['img'] = film.css('img.thumbnail-img').attrib['src']\n",
    "            except:\n",
    "                item['img'] = 'None'\n",
    "\n",
    "\n",
    "            # Auteur du film\n",
    "            try:\n",
    "                item['author'] = film.css('a.blue-link::text').extract()\n",
    "            except:\n",
    "                item['author'] = 'None'\n",
    "           \n",
    "            # Durée du film\n",
    "            try:\n",
    "                item['time'] = str(film.css('div.meta-body-item.meta-body-info::text')[0].get()).strip()\n",
    "            except:\n",
    "                item['time'] = 'None'\n",
    "\n",
    "            # Genre cinématographique\n",
    "            try:\n",
    "                item['genre'] = film.css('div.meta-body-item.meta-body-info')[0].css('span::text')[1:].extract()\n",
    "            except:\n",
    "                 item['genre'] = 'None'\n",
    "\n",
    "            # Score du film\n",
    "            try:\n",
    "                item['score'] = film.css('span.stareval-note::text')[:-1].extract()\n",
    "            except:\n",
    "                item['score'] = 'None'\n",
    "\n",
    "            # Description du film\n",
    "            try:\n",
    "                item['desc'] = str(film.css('div.content-txt::text').get()).strip()\n",
    "            except:\n",
    "                item['desc'] = 'None'\n",
    "\n",
    "            # Date de sortie\n",
    "            try:\n",
    "                item['release'] = str(film.css('span.date::text').get()).strip()\n",
    "            except:\n",
    "                item['release'] = 'None'\n",
    "\n",
    "\n",
    "            yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5tuGKHsiXLO"
   },
   "source": [
    "## 4.7 Ajoutez l'ensemble de votre code au fichier `allocine.py` se trouvant dans le dossier `spider`, exécutant la commande suivante afin d'obtenir le fichier `allocine.csv` contenant les données collectées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzo8p7naiXLO"
   },
   "outputs": [],
   "source": [
    "!cd WebCrawler/WebCrawler/spiders && scrapy crawl allocine -o allocine.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fFbZxGAiXLP"
   },
   "source": [
    "## 4.7 Importez la bibliothèque Pandas puis visualisez votre collecte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4z-ZPA-BiXLP",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre</th>\n",
       "      <th>img</th>\n",
       "      <th>release</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Au lieu de subtiliser un rêve, un voleur expér...</td>\n",
       "      <td>Science Fiction,Thriller</td>\n",
       "      <td>https://fr.web.img6.acsta.net/c_310_420/medias...</td>\n",
       "      <td>12 août 2020</td>\n",
       "      <td>4,1,4,5</td>\n",
       "      <td>2h 28min</td>\n",
       "      <td>Inception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masaki Kobayashi</td>\n",
       "      <td>Japon, 17ème siècle. Le samouraï Tsugumo vient...</td>\n",
       "      <td>Drame</td>\n",
       "      <td>https://fr.web.img6.acsta.net/c_310_420/medias...</td>\n",
       "      <td>13 août 2008</td>\n",
       "      <td>4,6,4,4</td>\n",
       "      <td>2h 13min</td>\n",
       "      <td>Harakiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>1954. Teddy Daniels et Chuck Aule enquêtent su...</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://fr.web.img2.acsta.net/c_310_420/medias...</td>\n",
       "      <td>None</td>\n",
       "      <td>3,8,4,4</td>\n",
       "      <td>2h 17min</td>\n",
       "      <td>Shutter Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>L'odyssée sanglante et burlesque de petits mal...</td>\n",
       "      <td>Policier,Thriller</td>\n",
       "      <td>https://fr.web.img2.acsta.net/c_310_420/medias...</td>\n",
       "      <td>None</td>\n",
       "      <td>4,4,4,5</td>\n",
       "      <td>2h 29min</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>Un mystérieux desperado pourchasse sans relâch...</td>\n",
       "      <td>Western</td>\n",
       "      <td>https://fr.web.img3.acsta.net/c_310_420/pictur...</td>\n",
       "      <td>10 octobre 2018</td>\n",
       "      <td>4,0,4,5</td>\n",
       "      <td>2h 55min</td>\n",
       "      <td>Il était une fois dans l'Ouest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>Rebellion dans un hôpital psychiatrique à l'in...</td>\n",
       "      <td>Drame</td>\n",
       "      <td>data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...</td>\n",
       "      <td>16 septembre 2009</td>\n",
       "      <td>5,0,4,5</td>\n",
       "      <td>2h 09min</td>\n",
       "      <td>Vol au-dessus d'un nid de coucou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Batman entreprend de démanteler les dernières ...</td>\n",
       "      <td>Action,Thriller</td>\n",
       "      <td>data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...</td>\n",
       "      <td>None</td>\n",
       "      <td>4,0,4,5</td>\n",
       "      <td>2h 32min</td>\n",
       "      <td>The Dark Knight, Le Chevalier Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Gérard Oury</td>\n",
       "      <td>En 1942, un avion anglais est abattu par les A...</td>\n",
       "      <td>Comédie</td>\n",
       "      <td>data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...</td>\n",
       "      <td>13 juillet 2016</td>\n",
       "      <td>3,8,4,3</td>\n",
       "      <td>2h 12min</td>\n",
       "      <td>La Grande Vadrouille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Stanley Kubrick</td>\n",
       "      <td>Écrivain, Jack Torrance est engagé comme gardi...</td>\n",
       "      <td>Epouvante-horreur,Thriller</td>\n",
       "      <td>data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...</td>\n",
       "      <td>22 mai 2019</td>\n",
       "      <td>4,0,4,3</td>\n",
       "      <td>2h 23min</td>\n",
       "      <td>Shining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Alfred Hitchcock</td>\n",
       "      <td>Le publiciste Roger Tornhill se retrouve par e...</td>\n",
       "      <td>Aventure,Policier</td>\n",
       "      <td>data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...</td>\n",
       "      <td>None</td>\n",
       "      <td>4,6,4,3</td>\n",
       "      <td>2h 16min</td>\n",
       "      <td>La Mort aux trousses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                               desc  \\\n",
       "0   Christopher Nolan  Au lieu de subtiliser un rêve, un voleur expér...   \n",
       "1    Masaki Kobayashi  Japon, 17ème siècle. Le samouraï Tsugumo vient...   \n",
       "2     Martin Scorsese  1954. Teddy Daniels et Chuck Aule enquêtent su...   \n",
       "3   Quentin Tarantino  L'odyssée sanglante et burlesque de petits mal...   \n",
       "4        Sergio Leone  Un mystérieux desperado pourchasse sans relâch...   \n",
       "..                ...                                                ...   \n",
       "85       Milos Forman  Rebellion dans un hôpital psychiatrique à l'in...   \n",
       "86  Christopher Nolan  Batman entreprend de démanteler les dernières ...   \n",
       "87        Gérard Oury  En 1942, un avion anglais est abattu par les A...   \n",
       "88    Stanley Kubrick  Écrivain, Jack Torrance est engagé comme gardi...   \n",
       "89   Alfred Hitchcock  Le publiciste Roger Tornhill se retrouve par e...   \n",
       "\n",
       "                         genre  \\\n",
       "0     Science Fiction,Thriller   \n",
       "1                        Drame   \n",
       "2                     Thriller   \n",
       "3            Policier,Thriller   \n",
       "4                      Western   \n",
       "..                         ...   \n",
       "85                       Drame   \n",
       "86             Action,Thriller   \n",
       "87                     Comédie   \n",
       "88  Epouvante-horreur,Thriller   \n",
       "89           Aventure,Policier   \n",
       "\n",
       "                                                  img            release  \\\n",
       "0   https://fr.web.img6.acsta.net/c_310_420/medias...       12 août 2020   \n",
       "1   https://fr.web.img6.acsta.net/c_310_420/medias...       13 août 2008   \n",
       "2   https://fr.web.img2.acsta.net/c_310_420/medias...               None   \n",
       "3   https://fr.web.img2.acsta.net/c_310_420/medias...               None   \n",
       "4   https://fr.web.img3.acsta.net/c_310_420/pictur...    10 octobre 2018   \n",
       "..                                                ...                ...   \n",
       "85  data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...  16 septembre 2009   \n",
       "86  data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...               None   \n",
       "87  data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...    13 juillet 2016   \n",
       "88  data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...        22 mai 2019   \n",
       "89  data:image/gif;base64,R0lGODlhAwAEAIAAAAAAAAAA...               None   \n",
       "\n",
       "      score      time                               title  \n",
       "0   4,1,4,5  2h 28min                           Inception  \n",
       "1   4,6,4,4  2h 13min                            Harakiri  \n",
       "2   3,8,4,4  2h 17min                      Shutter Island  \n",
       "3   4,4,4,5  2h 29min                        Pulp Fiction  \n",
       "4   4,0,4,5  2h 55min      Il était une fois dans l'Ouest  \n",
       "..      ...       ...                                 ...  \n",
       "85  5,0,4,5  2h 09min    Vol au-dessus d'un nid de coucou  \n",
       "86  4,0,4,5  2h 32min  The Dark Knight, Le Chevalier Noir  \n",
       "87  3,8,4,3  2h 12min                La Grande Vadrouille  \n",
       "88  4,0,4,3  2h 23min                             Shining  \n",
       "89  4,6,4,3  2h 16min                La Mort aux trousses  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\lahou\\Documents\\IPSSI\\WebScraping\\WebCrawler\\WebCrawler\\spiders\\allocine.csv', encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWwF7o_DiXLP"
   },
   "source": [
    "# Partie 2 - Cotations boursières du CAC40 - [Boursorama](https://www.boursorama.com/bourse/actions/palmares/france/page-1?france_filter%5Bmarket%5D=1rPCAC)\n",
    "\n",
    "\n",
    "<img src='data:image/png;base64,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'>\n",
    "\n",
    "\n",
    "\n",
    "L'objectif de cet exercice sera de collecter les données en temps réelle des actions du CAC40.\n",
    "Les données que nous collecterons serons :\n",
    "\n",
    "- le nom de l'indice boursier\n",
    "- le cours de l'action\n",
    "- la variation de l'action\n",
    "- la valeur la plus haute de la séance\n",
    "- la valeur la plus basse\n",
    "- la valeur d'ouverture\n",
    "- la date et l'heure de la collecte\n",
    "\n",
    "\n",
    "## Lancez le projet scrapy\n",
    "\n",
    "Créez le projet scrapy nomé `boursorama` en utilisant le lien suivant `https://www.boursorama.com/bourse/actions/palmares/france/page-1`.\n",
    "\n",
    "Pour rappel la commande scrapy pour génére un nouveau spider est la suivante : \n",
    "\n",
    "`scrapy genspider nom_du_projet adresse_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr04zt80iXLQ"
   },
   "outputs": [],
   "source": [
    "!cd WebCrawler && scrapy genspider (nom_du_projet::à compléter) (url_du_projet::à compléter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yrj1tdZviXLQ"
   },
   "source": [
    "## Modifiez le fichier items.py en ajoutant les champs à collecter\n",
    "\n",
    "Ajoutez une class `ReviewsBoursoramaItem(scrapy.Item)` puis les champs avec la nomenclature `name = scrapy.Field()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4CdiIVwiXLQ"
   },
   "source": [
    "## Lancez le shell scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUDEYKAJiXLQ"
   },
   "source": [
    "`scrapy shell`\n",
    "\n",
    "`url = 'https://www.boursorama.com/bourse/actions/palmares/france/page-1?france_filter%5Bmarket%5D=1rPCAC'`\n",
    "\n",
    "`fetch(url)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHOTe-TMiXLQ"
   },
   "source": [
    "## Compléter le code suivant puis ajoutez-le au fichier `boursorama.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQQpUbnUiXLQ"
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy import Request\n",
    "from WebCrawler.items import #Importe la class contenant vos items (champs collectés) ==> à compléter\n",
    "import time\n",
    "\n",
    "class BoursoramaSpider(scrapy.Spider):\n",
    "    name = 'boursorama'\n",
    "    allowed_domains = ['finance.yahoo.com']\n",
    "    start_urls = #[Liste des URL à compléter]\n",
    "\n",
    "    def start_requests(self):\n",
    "        for url in self.start_urls:\n",
    "            yield Request(url=url, callback=self.parse_boursorama)\n",
    "            \n",
    "    def parse_boursorama(self, response):\n",
    "        liste_indices = response.css('tr.c-table__row')[1:]\n",
    "        \n",
    "        for indices in liste_indices:\n",
    "            item = #importer la class Items du projet provenant du fichier items.py\n",
    "            \n",
    "            #indice boursier\n",
    "            try: \n",
    "              item['indice'] = #à compléter\n",
    "            except:\n",
    "              item['indice'] = 'None'\n",
    "            \n",
    "            #indice cours de l'action\n",
    "            try: \n",
    "              item['cours'] = #à compléter\n",
    "            except:item['cours'] = 'None'\n",
    "            \n",
    "            #Variation de l'action\n",
    "            try: \n",
    "              item['var'] = #à compléter\n",
    "            except:\n",
    "              item['var'] = 'None'\n",
    "            \n",
    "            #Valeur la plus haute\n",
    "            try: \n",
    "              item['hight'] = #à compléter\n",
    "            except:\n",
    "              item['hight'] = 'None'\n",
    "            \n",
    "            #Valeur la plus basse\n",
    "            try: \n",
    "              item['low'] = #à compléter\n",
    "            except:\n",
    "              item['low'] = 'None'\n",
    "\n",
    "            #Valeur d'ouverture\n",
    "            try: \n",
    "              item['open_'] = #à compléter\n",
    "            except:\n",
    "              item['open_'] = 'None'\n",
    "\n",
    "            #Date de la collecte\n",
    "            try: \n",
    "              item['time'] = #à compléter\n",
    "            except:\n",
    "              item['time'] = 'None'\n",
    "\n",
    "            \n",
    "            yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CW6by-UiXLQ"
   },
   "source": [
    "## Executez la commande suivante afin de collecter vos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xaWKWlViXLR"
   },
   "outputs": [],
   "source": [
    "!cd WebCrawler/WebCrawler/spiders && scrapy crawl (nom_du_projet::à compléter) -o (nom_du_fichier_csv::à compléter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cDVct8giXLR"
   },
   "source": [
    "# Bonus - [MyAnimeListe](https://myanimelist.net/manga.php?letter=A)\n",
    "\n",
    "<img src='https://image.myanimelist.net/ui/OK6W_koKDTOqqqLDbIoPArR89MP-ulHxaLCJ2P-BfXg'>\n",
    "\n",
    "Reproduisez l'ensemble de la procédure en collectant les données du site [MyAnimeListe](https://myanimelist.net/manga.php?letter=A).\n",
    "\n",
    "Les données à collecter : \n",
    "- le nom des animés\n",
    "- l'image des animés\n",
    "- la description des animés.\n",
    "\n",
    "Utilisez la class `DataBase` pour stoquer vos donneés dans une base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuCtNZi6iXLR"
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "\n",
    "class DataBase():\n",
    "    def __init__(self, name_database='database'):\n",
    "        self.name = name_database\n",
    "        self.url = f\"sqlite:///{name_database}.db\"\n",
    "        self.engine = db.create_engine(self.url)\n",
    "        self.connection = self.engine.connect()\n",
    "        self.metadata = db.MetaData()\n",
    "        self.table = self.engine.table_names()\n",
    "       \n",
    "    \n",
    "    def create_table(self, name_table, **kwargs):\n",
    "        colums = [db.Column(k, v, primary_key = True) if 'id_' in k else db.Column(k, v) for k,v in kwargs.items()]\n",
    "        db.Table(name_table, self.metadata, *colums)\n",
    "        self.metadata.create_all(self.engine)\n",
    "        print(f\"Table : '{name_table}' are created succesfully\")\n",
    "        \n",
    "    def read_table(self, name_table, return_keys=False):\n",
    "        table = db.Table(name_table, self.metadata, autoload=True, autoload_with=self.engine)\n",
    "        if return_keys:table.columns.keys() \n",
    "        else : return table\n",
    "        \n",
    "        \n",
    "    def add_row(self, name_table, **kwarrgs):\n",
    "        name_table = self.read_table(name_table)\n",
    "        \n",
    "        stmt = (\n",
    "            db.insert(name_table).\n",
    "            values(kwarrgs)\n",
    "        )\n",
    "        self.connection.execute(stmt)\n",
    "        print(f'Row id added')\n",
    "        \n",
    "        \n",
    "    def delete_row_by_id(self, table, id_):\n",
    "        name_table = self.read_table(name_table) \n",
    "        \n",
    "        stmt = (\n",
    "            db.delete(name_table).\n",
    "            where(students.c.id_ == id_)\n",
    "            )\n",
    "        self.connection.execute(stmt)\n",
    "        print(f'Row id {id_} deleted')\n",
    "        \n",
    "    def select_table(self, name_table):\n",
    "        name_table = self.read_table(name_table)       \n",
    "        stm = db.select([name_table])\n",
    "        return self.connection.execute(stm).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNdFB96TiXLR"
   },
   "outputs": [],
   "source": [
    "#Générer un projet scrapy\n",
    "!cd WebCrawler && scrapy genspider manga https://myanimelist.net/manga.php?letter=A\n",
    "    \n",
    "# Collecter les données\n",
    "!cd WebCrawler/WebCrawler/spiders && scrapy crawl (nom_du_projet::à compléter) -o (nom_du_fichier_CSV::à compléter)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
